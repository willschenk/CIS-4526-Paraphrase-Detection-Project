{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca24ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev With Label Shape: (724, 4)\n",
      "Train With Label Shape: (4077, 4)\n",
      "Test Without Label Shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn import preprocessing \n",
    "\n",
    "## Import Data ## \n",
    "\n",
    "# Import training set \n",
    "with open('train_with_label.txt') as file:\n",
    "    train_buffer = file.readlines()\n",
    "    train = pd.DataFrame([row.split('\\t') for row in train_buffer], columns=['ID', 'sentence1', 'sentence2', 'groundTruth'])\n",
    "    train.groundTruth = train.groundTruth.apply(lambda x: int(x.rstrip()))\n",
    "\n",
    "# Import dev set \n",
    "with open('dev_with_label.txt') as file:\n",
    "    dev_buffer = file.readlines()\n",
    "    dev = pd.DataFrame([row.split('\\t') for row in dev_buffer], columns=['ID', 'sentence1', 'sentence2', 'groundTruth'])\n",
    "    dev.groundTruth = dev.groundTruth.apply(lambda x: int(x.rstrip()))\n",
    "\n",
    "# Import testing set \n",
    "with open('test_without_label.txt') as file:\n",
    "    test_buffer = file.readlines()\n",
    "    test = pd.DataFrame([row.split('\\t') for row in test_buffer], columns=['ID', 'sentence1', 'sentence2']) \n",
    "\n",
    "# Print out shapes \n",
    "print(\"Dev With Label Shape: \" + str(dev.shape)) \n",
    "print(\"Train With Label Shape: \" + str(train.shape)) \n",
    "print(\"Test Without Label Shape: \" + str(test.shape)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76a47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from Levenshtein import distance as lev \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "## Generate Features ## \n",
    "\n",
    "# Function: Generate features provided two sentences \n",
    "def featureCreation(frame): # Pass in the information  \n",
    "    df = pd.DataFrame(frame) # Convert to dataFrame \n",
    "    \n",
    "    # Vectorize each sentence and clean each element \n",
    "    df['words1'] = df['sentence1'].str.replace('[^\\'0-9A-Za-z ]+', '').str.lower().str.replace(\" '\", \"'\").str.replace(\"  \", \" \").str.split(' ') \n",
    "    df['words2'] = df['sentence2'].str.replace('[^\\'0-9A-Za-z ]+', '').str.lower().str.replace(\" '\", \"'\").str.replace(\"  \", \" \").str.split(' ')\n",
    "    \n",
    "    # Find commonality between words \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    df['words1'] = df.apply(lambda x: ([lemmatizer.lemmatize(word) for word in x['words1']]), axis = 1) \n",
    "    df['words2'] = df.apply(lambda x: ([lemmatizer.lemmatize(word) for word in x['words2']]), axis = 1) \n",
    "\n",
    "    # Find the number of words in common, then divide by the average number of words between the two sentences \n",
    "    df['WordsInCommon/AverageLen'] = df.apply(lambda x: (len(np.intersect1d(x['words1'],x['words2']))) / (len(x['words1']) + len(x['words2']))/2, axis = 1)\n",
    "    \n",
    "    # Obtain the difference in length between the two sentences \n",
    "    df['differenceInLength'] = df.apply(lambda x: abs(len(x['words1']) - len(x['words2'])), axis = 1)\n",
    "\n",
    "    ## Subset Function ## \n",
    "    # This sub-function counts the number of times each sequential subset of words of length \"difference\", appear in both sentences. \n",
    "    # e.g. Difference = 2 \n",
    "    #      Sentence 1: How are you? Sentence 2: Who are you? \n",
    "    #                  how are you              who are you \n",
    "    #     subset_1    [how are]             != [who are], != [are you] \n",
    "    #     subset_2    [are you]             != [who are],  = [are you] \n",
    "    #     Output = 1 \n",
    "    def subsetCounter(a, b, difference): \n",
    "        count = 0 \n",
    "        for i in range(len(a) - difference - 1): # Create a subset from a \n",
    "            subset1 = a[i:(i + difference)] \n",
    "            for j in range(len(b) - difference - 1): # See if this subset is in b \n",
    "                subset2 = b[j:(j + difference)] \n",
    "                if(subset1 == subset2): \n",
    "                    count = count + 1 \n",
    "                    # print(\"Subset1: \" + str(subset1) + \"\\tSubset2: \" + str(subset2)) # Test \n",
    "        return count \n",
    "\n",
    "    # Sub-function to return maximum between (a,b) and (b,a) \n",
    "    def subsetWords(a, b, difference): \n",
    "        count1 = subsetCounter(a, b, difference) \n",
    "        count2 = subsetCounter(b, a, difference) \n",
    "        return np.maximum(count1, count2)\n",
    "    \n",
    "    # Apply the above sub-functions for subsets of length 2, 3, 4, 5, and 6 \n",
    "    df['subsets2'] = df.apply(lambda x: subsetWords(x['words1'], x['words2'], 2) / ((len(x['words1']) + len(x['words1'])) / 2), axis = 1) \n",
    "    df['subsets3'] = df.apply(lambda x: subsetWords(x['words1'], x['words2'], 3) / ((len(x['words1']) + len(x['words1'])) / 2), axis = 1) \n",
    "    df['subsets4'] = df.apply(lambda x: subsetWords(x['words1'], x['words2'], 4) / ((len(x['words1']) + len(x['words1'])) / 2), axis = 1) \n",
    "    df['subsets5'] = df.apply(lambda x: subsetWords(x['words1'], x['words2'], 5) / ((len(x['words1']) + len(x['words1'])) / 2), axis = 1)\n",
    "    df['subsets6'] = df.apply(lambda x: subsetWords(x['words1'], x['words2'], 6) / ((len(x['words1']) + len(x['words2'])) / 2), axis = 1)\n",
    "\n",
    "    # BiLingual Evaluation Understudy Score \n",
    "    df['Bleu Score'] = df.apply(lambda x: nltk.translate.bleu_score.sentence_bleu([x['words1']], x['words2'], weights = (1, 0, 0, 0)), axis = 1) \n",
    "\n",
    "    # Levenshtein Score \n",
    "    df['Levenshtein'] = 0\n",
    "    for i in range(len(df)): \n",
    "        df['Levenshtein'].iloc[i] = lev(df['words1'].iloc[i], df['words2'].iloc[i]) / ((len(df['words1'].iloc[i]) + len(df['words2'].iloc[i])) / 2) \n",
    "    \n",
    "    # Uncommon words in common score / length score: \n",
    "    with open('1-1000.txt') as file:\n",
    "        test_buffer = file.readlines()\n",
    "#       dictionary250 = pd.DataFrame([row.split('\\n') for row in test_buffer], columns=['Word', 'Null']).head(250)\n",
    "#       dictionary250 = set(dictionary250['Word']) # Convert to set \n",
    "        dictionary1000 = pd.DataFrame([row.split('\\n') for row in test_buffer], columns=['Word', 'Null']).head(1000)\n",
    "        dictionary1000 = set(dictionary1000['Word']) # Convert to set \n",
    "    \n",
    "#     df['words1_Outside_dictionary250'] = df['words1'].apply(lambda x: list(filter(None, set(x).difference(dictionary250)))) \n",
    "#     df['words2_Outside_dictionary250'] = df['words2'].apply(lambda x: list(filter(None, set(x).difference(dictionary250))))\n",
    "#     df['Outside_dictionary250_Common / Length'] = df.apply(lambda x: (len(np.intersect1d(x['words1_Outside_dictionary250'],x['words2_Outside_dictionary250']))) / (len(x['words1_Outside_dictionary250']) + len(x['words2_Outside_dictionary250']) + 1)/2, axis = 1)\n",
    "    \n",
    "    df['words1_Outside_dictionary1000'] = df['words1'].apply(lambda x: list(filter(None, set(x).difference(dictionary1000)))) \n",
    "    df['words2_Outside_dictionary1000'] = df['words2'].apply(lambda x: list(filter(None, set(x).difference(dictionary1000))))\n",
    "    df['Outside_dictionary1000_Common / Length'] = df.apply(lambda x: (len(np.intersect1d(x['words1_Outside_dictionary1000'],x['words2_Outside_dictionary1000']))) / (len(x['words1_Outside_dictionary1000']) + len(x['words2_Outside_dictionary1000']) + 1)/2, axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b341026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jq/drn2hrr90kv396cxlgjbbryw0000gn/T/ipykernel_14770/891423711.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['words1'] = df['sentence1'].str.replace('[^\\'0-9A-Za-z ]+', '').str.lower().str.replace(\" '\", \"'\").str.replace(\"  \", \" \").str.split(' ')\n",
      "/var/folders/jq/drn2hrr90kv396cxlgjbbryw0000gn/T/ipykernel_14770/891423711.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['words2'] = df['sentence2'].str.replace('[^\\'0-9A-Za-z ]+', '').str.lower().str.replace(\" '\", \"'\").str.replace(\"  \", \" \").str.split(' ')\n",
      "/Users/christopherschenk/opt/anaconda3/lib/python3.9/site-packages/nltk/translate/bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/christopherschenk/opt/anaconda3/lib/python3.9/site-packages/nltk/translate/bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/christopherschenk/opt/anaconda3/lib/python3.9/site-packages/nltk/translate/bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/christopherschenk/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros in the training set: 1039\n",
      "Number of ones in the training set: 3038\n",
      "New number of zeros in the training set: 3038\n",
      "New number of ones in the training set: 3038\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn import linear_model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "from sklearn.utils import resample \n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Generate the features the datasets: \n",
    "train = featureCreation(train) \n",
    "dev = featureCreation(dev) \n",
    "test = featureCreation(test) \n",
    "\n",
    "# Upsampling: \n",
    "print(\"Number of zeros in the training set: \" + str((train['groundTruth'] == 0).sum())) \n",
    "print(\"Number of ones in the training set: \" + str((train['groundTruth'] == 1).sum())) \n",
    "\n",
    "# Thus, an upsampling must be preformed: \n",
    "zeros = train[train['groundTruth'] == 0] \n",
    "ones = train[train['groundTruth'] == 1]\n",
    "zeros = resample(zeros, replace = True, n_samples = len(ones), random_state = 1)\n",
    "train = pd.concat([zeros, ones]) \n",
    "\n",
    "print(\"New number of zeros in the training set: \" + str((train['groundTruth'] == 0).sum())) \n",
    "print(\"New number of ones in the training set: \" + str((train['groundTruth'] == 1).sum())) \n",
    "\n",
    "# Set features that will be used in the model:  \n",
    "# Dropped differentInLength \n",
    "X_train = train[['WordsInCommon/AverageLen', 'subsets2', 'subsets3', 'subsets4', 'subsets5', 'subsets6', 'Bleu Score', 'Levenshtein', 'Outside_dictionary1000_Common / Length']] \n",
    "y_train = train['groundTruth'] \n",
    "X_dev = dev[['WordsInCommon/AverageLen', 'subsets2', 'subsets3', 'subsets4', 'subsets5', 'subsets6', 'Bleu Score', 'Levenshtein', 'Outside_dictionary1000_Common / Length']]\n",
    "y_dev = dev['groundTruth'] \n",
    "X_test = test[['WordsInCommon/AverageLen', 'subsets2', 'subsets3', 'subsets4', 'subsets5', 'subsets6', 'Bleu Score', 'Levenshtein', 'Outside_dictionary1000_Common / Length']] \n",
    "\n",
    "# Normalize the data: \n",
    "scaler = MinMaxScaler() \n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_dev = scaler.transform(X_dev) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18aed33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.75\n",
      "Accuracy Percentage (%) :  75.0\n",
      "The following is adjusted by resampling in the cell above. \n",
      "Number of zeros predicted: 411\n",
      "Number of ones predicted: 313\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from numpy import mean \n",
    "from numpy import std \n",
    "\n",
    "# SVM Model \n",
    "model4 = SVC(kernel = 'rbf', probability = True, C = 10, gamma = .7) \n",
    "model4.fit(X_train, y_train)\n",
    "y_pred = model4.predict(X_dev) \n",
    "\n",
    "accuracy = metrics.accuracy_score(y_dev, y_pred)\n",
    "accuracy_percentage = 100 * accuracy \n",
    "\n",
    "print('Accuracy : ', accuracy) \n",
    "print(\"Accuracy Percentage (%) : \", accuracy_percentage) \n",
    "\n",
    "# Test Feature Importance: \n",
    "perm_importance = permutation_importance(model4, X_dev, y_dev)\n",
    "\n",
    "feature_names = ['WordsInCommon/AverageLen', 'subsets2', 'subsets3', 'subsets4', 'subsets5', 'subsets6', 'Bleu Score', 'Levenshtein', 'Outside_dictionary1000_Common / Length']\n",
    "features = np.array(feature_names)\n",
    "\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\") \n",
    "\n",
    "print(\"The following is adjusted by resampling in the cell above. \") \n",
    "print(\"Number of zeros predicted: \" + str((y_pred == 0).sum())) \n",
    "print(\"Number of ones predicted: \" + str((y_pred == 1).sum())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8600b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros predicted: 777\n",
      "Number of ones predicted: 223\n"
     ]
    }
   ],
   "source": [
    "# Output Prediciton for the testing set: \n",
    "y_pred = model4.predict(X_test) \n",
    "\n",
    "# Create submission file: \n",
    "test['y_pred'] = y_pred.tolist() \n",
    "submission = test[['ID', 'y_pred']] \n",
    "submission.to_csv('Will_Schenk_test_result.txt', sep ='\\t', header = False, index = False)\n",
    "\n",
    "\n",
    "# This can be made 500, and 500 by upsampling the number of ones in the testing set. \n",
    "# But, this will decrease the accuracy in the dev set. \n",
    "# I used KFold Cross validation, which returned the same accuracy, so overfitting is not an issue. \n",
    "# Instead, the majority of 0 samples are correctly classified, and the majority of sample classified as 1, are 1. \n",
    "\n",
    "print(\"Number of zeros predicted: \" + str((y_pred == 0).sum())) \n",
    "print(\"Number of ones predicted: \" + str((y_pred == 1).sum())) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
